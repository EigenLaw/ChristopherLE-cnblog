{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#支线任务-爬虫\" data-toc-modified-id=\"支线任务-爬虫-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>支线任务-爬虫</a></span></li><li><span><a href=\"#豆瓣影评\" data-toc-modified-id=\"豆瓣影评-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>豆瓣影评</a></span></li><li><span><a href=\"#获取图片地址\" data-toc-modified-id=\"获取图片地址-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>获取图片地址</a></span></li><li><span><a href=\"#同时获取图片及命名\" data-toc-modified-id=\"同时获取图片及命名-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>同时获取图片及命名</a></span></li><li><span><a href=\"#伪装Header，爬取百度百科中北京地铁站\" data-toc-modified-id=\"伪装Header，爬取百度百科中北京地铁站-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>伪装Header，爬取百度百科中北京地铁站</a></span></li><li><span><a href=\"#手动+自动的Selenium窃取90%网站\" data-toc-modified-id=\"手动+自动的Selenium窃取90%网站-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>手动+自动的Selenium窃取90%网站</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 支线任务-爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 我还在犹豫要不要写爬虫这篇，因为网上已经有大量爬虫相关资源，爬虫也不是以研究为主，而是一个获取数据的手段。\n",
    "**书写目的**\n",
    "- 数据数量和质量对你运行模型的效果有着重要影响；\n",
    "- 如果数据购买昂贵又没有现成数据下载，不论个人还是公司都会首选爬虫；\n",
    "- 不需要深入爬虫知识（比如Scrapy爬虫工程），就可以获取大部分网站数据；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**装包提示：**\n",
    "- 装包用pip install XXX，Baidu一下有很多指导帖\n",
    "- 学会Baidu谷歌能够让你在之后的路上走得更远更自信"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 豆瓣影评"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use Requests and regular expression\n",
    "\n",
    "__正则表达式-重要的事情说两遍__\n",
    "\n",
    "- [c,m,f]an: can, man, fan; [^b]og to skip bog\n",
    "- [^a-z]\\w+ skip lower case begined string; \\w means [A-Za-z0-9]; \\d means [0-9]\n",
    "- z{3} match z three times: uzzz, wuzzzz; .{2,6} match string with length of 2-6\n",
    "- \\? match ?\n",
    "- whitespace: space (␣), the tab (\\t), the new line (\\n) and the carriage return (\\r) \n",
    "- \\s will match any of the specific whitespaces above\n",
    "- \\D represents any non-digit character, \\S any non-whitespace character, and \\W any non-alphanumeric\n",
    "- ^Mission: successful\\$ ^为字符串开始 and $为字符串结尾\n",
    "- ^(file_\\w+) can match file_record_transcript in file_record_transcript.pdf\n",
    "- ^([A-Z]\\w{2} (\\d{4})) 括号中为提取的信息，此处不但提取Jan 1987，还提取1987\n",
    "- ^I love cats|I love dogs\\$ match \"I love cats\"或\"I love dogs\"\n",
    "- ^The.* match string starting with \"The\"\n",
    "\n",
    "> 正则表达式的练习在线网址: https://regexone.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "url = \"https://movie.douban.com/review/best/\"\n",
    "total1 = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern1 = re.compile(\"https://movie.douban.com/review/\\d+/\")\n",
    "review_url_list = pattern1.findall(total1)\n",
    "review_url_list = list(set(review_url_list))#remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "review = []\n",
    "\n",
    "for url in review_url_list:\n",
    "    total = requests.get(url).text\n",
    "    pattern2 = re.compile(\"<p>.*</p>\")\n",
    "    review0 = str(pattern2.findall(total))\n",
    "    review.append(review0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF1 = pd.DataFrame({\"影评\": review, \"网址\": review_url_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>影评</th>\n",
       "      <th>网址</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['&lt;p&gt;一看到&lt;span style=\"font-weight: bold;\"&gt;[巨齿鲨]...</td>\n",
       "      <td>https://movie.douban.com/review/9589353/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['&lt;p&gt;出租车载着这些好坏参半的社会群像，一如装下整个国家，徐徐往前，找寻方向。&lt;/p&gt;&lt;...</td>\n",
       "      <td>https://movie.douban.com/review/9591858/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['&lt;p&gt;《情书》是一部经典的初恋向青春电影，有着日本电影的典型特色，带着死亡的气息，哀凄而...</td>\n",
       "      <td>https://movie.douban.com/review/9590896/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['&lt;p&gt;10、我可能更想看两个小时的巨齿鲨大战深海乌贼。 &lt;/p&gt;']</td>\n",
       "      <td>https://movie.douban.com/review/9591927/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['&lt;p&gt;电影自己剧透，叫草蛇灰线。我剧透，就叫丧心病狂。&lt;/p&gt;&lt;/div&gt;&lt;p&gt;对我们这...</td>\n",
       "      <td>https://movie.douban.com/review/9591655/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['&lt;p&gt;前阵子，我犯了个错。&lt;/p&gt;&lt;p&gt;我在文章里说，当下的大陆喜剧，有两大派系分庭抗礼...</td>\n",
       "      <td>https://movie.douban.com/review/9590031/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['&lt;p&gt;假如你现在想看一部日本电影，又觉得大师们的片子太厚重，不易接近，新电影又拿不准看个...</td>\n",
       "      <td>https://movie.douban.com/review/9590937/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['&lt;p&gt;&lt;/p&gt;&lt;h2&gt;一&lt;/h2&gt;&lt;p&gt;&lt;span style=\"font-weight...</td>\n",
       "      <td>https://movie.douban.com/review/9592082/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['&lt;p&gt;学长他就像我生命中的灵感，他让我了解爱的积极意义，他就像是让我一直前进的动力，&lt;/...</td>\n",
       "      <td>https://movie.douban.com/review/9593388/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['&lt;p&gt;当你走在熙熙攘攘的街头，忽然，一张似曾相识的脸出现在眼帘之中。未及细看，那身影已翩...</td>\n",
       "      <td>https://movie.douban.com/review/9590829/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  影评  \\\n",
       "0  ['<p>一看到<span style=\"font-weight: bold;\">[巨齿鲨]...   \n",
       "1  ['<p>出租车载着这些好坏参半的社会群像，一如装下整个国家，徐徐往前，找寻方向。</p><...   \n",
       "2  ['<p>《情书》是一部经典的初恋向青春电影，有着日本电影的典型特色，带着死亡的气息，哀凄而...   \n",
       "3               ['<p>10、我可能更想看两个小时的巨齿鲨大战深海乌贼。 </p>']   \n",
       "4  ['<p>电影自己剧透，叫草蛇灰线。我剧透，就叫丧心病狂。</p></div><p>对我们这...   \n",
       "5  ['<p>前阵子，我犯了个错。</p><p>我在文章里说，当下的大陆喜剧，有两大派系分庭抗礼...   \n",
       "6  ['<p>假如你现在想看一部日本电影，又觉得大师们的片子太厚重，不易接近，新电影又拿不准看个...   \n",
       "7  ['<p></p><h2>一</h2><p><span style=\"font-weight...   \n",
       "8  ['<p>学长他就像我生命中的灵感，他让我了解爱的积极意义，他就像是让我一直前进的动力，</...   \n",
       "9  ['<p>当你走在熙熙攘攘的街头，忽然，一张似曾相识的脸出现在眼帘之中。未及细看，那身影已翩...   \n",
       "\n",
       "                                         网址  \n",
       "0  https://movie.douban.com/review/9589353/  \n",
       "1  https://movie.douban.com/review/9591858/  \n",
       "2  https://movie.douban.com/review/9590896/  \n",
       "3  https://movie.douban.com/review/9591927/  \n",
       "4  https://movie.douban.com/review/9591655/  \n",
       "5  https://movie.douban.com/review/9590031/  \n",
       "6  https://movie.douban.com/review/9590937/  \n",
       "7  https://movie.douban.com/review/9592082/  \n",
       "8  https://movie.douban.com/review/9593388/  \n",
       "9  https://movie.douban.com/review/9590829/  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF1#可以看到影评中还有许多源码需要去除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取图片地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2552058346.jpg',\n",
       " 'https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554545271.jpg',\n",
       " 'https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2551353482.jpg',\n",
       " 'https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554775210.jpg',\n",
       " 'https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554401295.jpg']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "url = \"https://movie.douban.com/\"\n",
    "total = requests.get(url).text\n",
    "pattern1 = re.compile(\"https://movie.douban.com/subject/\\d+/\\?from=showing\")\n",
    "pattern2 = re.compile(\"https://img3.doubanio.com/view/photo/s_ratio_poster/public/p\\d+.jpg\")\n",
    "pattern2.findall(total)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img3.doubanio.com/view/photo/s_ratio_poster/public/p1910824951.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同时获取图片及命名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import string\n",
    "table=str.maketrans({key:None for key in string.punctuation})#防止文件命名中出现标点符号，移除 ? / , .\n",
    "\n",
    "def getAllImageLink():\n",
    "    for i in range(0,2):#可以设为100页或更高\n",
    "        if i==0:\n",
    "            url=\"http://www.dbmeinv.com\"\n",
    "        else:\n",
    "            url=\"https://www.dbmeinv.com/?pager_offset=\"+str(i+1)#自己寻找翻页后网址变化规律\n",
    "        html = urllib.request .urlopen(url).read()\n",
    "        soup = BeautifulSoup(html)\n",
    "        liResult = soup.findAll('li',attrs={\"class\":\"span3\"})\n",
    "        \n",
    "        for li in liResult:\n",
    "            imageEntityArray = li.findAll('img')\n",
    "            for image in imageEntityArray:\n",
    "                link = image.get('src')\n",
    "                imageName = image.get('title')\n",
    "                imageName=imageName.translate(table)\n",
    "                filesavepath = \"%s.png\" % imageName\n",
    "                urllib.request.urlretrieve(link,filesavepath)\n",
    "                \n",
    "getAllImageLink()               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 伪装Header，爬取百度百科中北京地铁站"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----The information of 1号线 is following...\n",
      "苹果园--古城: 2606m\n",
      "古城--八角游乐园: 1921m\n",
      "八角游乐园--八宝山: 1953m\n",
      "八宝山--玉泉路: 1479m\n",
      "玉泉路--五棵松: 1810m\n",
      "五棵松--万寿路: 1778m\n",
      "万寿路--公主坟: 1313m\n",
      "公主坟--军事博物馆: 1172m\n",
      "军事博物馆--木樨地: 1166m\n",
      "木樨地--南礼士路: 1291m\n",
      "南礼士路--复兴门: 424m\n",
      "复兴门--西单: 1590m\n",
      "西单--天安门西: 1217m\n",
      "天安门西--天安门东: 925m\n",
      "天安门东--王府井: 852m\n",
      "王府井--东单: 774m\n",
      "东单--建国门: 1230m\n",
      "建国门--永安里: 1377m\n",
      "永安里--国贸: 790m\n",
      "国贸--大望路: 1385m\n",
      "大望路--四惠: 1673m\n",
      "四惠--四惠东: 1714m\n",
      "\n",
      "----The information of 2号线 is following...\n",
      "西直门--车公庄: 909m\n",
      "车公庄--阜成门: 960m\n",
      "阜成门--复兴门: 1832m\n",
      "复兴门--长椿街: 1234m\n",
      "长椿街--宣武门: 929m\n",
      "宣武门--和平门: 851m\n",
      "和平门--前门: 1171m\n",
      "前门--崇文门: 1634m\n",
      "崇文门--北京站: 1023m\n",
      "北京站--建国门: 945m\n",
      "建国门--朝阳门: 1763m\n",
      "朝阳门--东四十条: 1027m\n",
      "东四十条--东直门: 824m\n",
      "东直门--雍和宫: 2228m\n",
      "雍和宫--安定门: 794m\n",
      "安定门--鼓楼大街: 1237m\n",
      "鼓楼大街--积水潭: 1766m\n",
      "积水潭--西直门: 1899m\n",
      "\n",
      "----The information of 4号线 is following...\n",
      "安河桥北--北宫门: 1363m\n",
      "北宫门--西苑: 1251m\n",
      "西苑--圆明园: 1672m\n",
      "圆明园--北京大学东门: 1295m\n",
      "北京大学东门--中关村: 887m\n",
      "中关村--海淀黄庄: 900m\n",
      "海淀黄庄--人民大学: 1063m\n",
      "人民大学--魏公村: 1051m\n",
      "魏公村--国家图书馆: 1658m\n",
      "国家图书馆--动物园: 1517m\n",
      "动物园--西直门: 1441m\n",
      "西直门--新街口: 1025m\n",
      "新街口--平安里: 1100m\n",
      "平安里--西四: 1100m\n",
      "西四--灵境胡同: 869m\n",
      "灵境胡同--西单: 1011m\n",
      "西单--宣武门: 815m\n",
      "宣武门--菜市口: 1152m\n",
      "菜市口--陶然亭: 1200m\n",
      "陶然亭--北京南站: 1643m\n",
      "北京南站--马家堡: 1480m\n",
      "马家堡--角门西: 827m\n",
      "角门西--公益西桥: 989m\n",
      "\n",
      "----The information of 5号线 is following...\n",
      "天通苑北--天通苑: 939m\n",
      "天通苑--天通苑南: 965m\n",
      "天通苑南--立水桥: 1544m\n",
      "立水桥--立水桥南: 1305m\n",
      "立水桥南--北苑路北: 1286m\n",
      "北苑路北--大屯路东: 3m\n",
      "大屯路东--惠新西街北口: 1838m\n",
      "惠新西街北口--惠新西街南口: 1122m\n",
      "惠新西街南口--和平西桥: 1025m\n",
      "和平西桥--和平里北街: 1059m\n",
      "和平里北街--雍和宫: 1151m\n",
      "雍和宫--北新桥: 866m\n",
      "北新桥--张自忠路: 791m\n",
      "张自忠路--东四: 1016m\n",
      "东四--灯市口: 848m\n",
      "灯市口--东单: 945m\n",
      "东单--崇文门: 821m\n",
      "崇文门--磁器口: 876m\n",
      "磁器口--天坛东门: 1183m\n",
      "天坛东门--蒲黄榆: 1m\n",
      "蒲黄榆--刘家窑: 905m\n",
      "刘家窑--宋家庄: 1670m\n",
      "\n",
      "----The information of 6号线 is following...\n",
      "海淀五路居--慈寿寺: 1508m\n",
      "慈寿寺--花园桥: 1431m\n",
      "花园桥--白石桥南: 1166m\n",
      "白石桥南--车公庄西: 1664m\n",
      "车公庄西--车公庄: 887m\n",
      "车公庄--平安里: 1443m\n",
      "平安里--北海北: 1321m\n",
      "北海北--南锣鼓巷: 1349m\n",
      "南锣鼓巷--东四: 1937m\n",
      "东四--朝阳门: 1399m\n",
      "朝阳门--东大桥: 1668m\n",
      "东大桥--呼家楼: 845m\n",
      "呼家楼--金台路: 1450m\n",
      "金台路--十里堡: 2036m\n",
      "十里堡--青年路: 1282m\n",
      "青年路--褡裢坡: 3999m\n",
      "褡裢坡--黄渠: 1238m\n",
      "黄渠--常营: 1854m\n",
      "常营--草房: 1405m\n",
      "草房--物资学院路: 2115m\n",
      "物资学院路--通州北关: 2557m\n",
      "通州北关--通运门: 1468m\n",
      "通运门--北运河西: 1543m\n",
      "北运河西--北运河东: 1599m\n",
      "北运河东--郝家府: 929m\n",
      "郝家府--东夏园: 1346m\n",
      "东夏园--潞城: 1194m\n",
      "\n",
      "----The information of 7号线 is following...\n",
      "北京西站--湾子: 935m\n",
      "湾子--达官营: 734m\n",
      "达官营--广安门内: 1874m\n",
      "广安门内--菜市口: 1374m\n",
      "菜市口--虎坊桥: 885m\n",
      "虎坊桥--珠市口: 1205m\n",
      "珠市口--桥湾: 869m\n",
      "桥湾--磁器口: 1016m\n",
      "磁器口--广渠门内: 1138m\n",
      "广渠门内--广渠门外: 1332m\n",
      "广渠门外--双井: 1241m\n",
      "双井--九龙山: 1311m\n",
      "九龙山--大郊亭: 781m\n",
      "大郊亭--百子湾: 865m\n",
      "百子湾--化工: 903m\n",
      "化工--南楼梓庄: 1464m\n",
      "南楼梓庄--欢乐谷景区: 906m\n",
      "欢乐谷景区--垡头: 1679m\n",
      "垡头--双合: 1304m\n",
      "双合--焦化厂: 1021m\n",
      "\n",
      "----The information of 北京地铁8号线 is following...\n",
      "朱辛庄--育知路: 2318m\n",
      "育知路--平西府: 1985m\n",
      "平西府--回龙观东大街: 2056m\n",
      "回龙观东大街--霍营: 1114m\n",
      "霍营--育新: 1894m\n",
      "育新--西小口: 1543m\n",
      "西小口--永泰庄: 1041m\n",
      "永泰庄--林萃桥: 2553m\n",
      "林萃桥--森林公园南门: 2555m\n",
      "森林公园南门--奥林匹克公园: 1016m\n",
      "奥林匹克公园--奥体中心: 1667m\n",
      "奥体中心--北土城: 900m\n",
      "北土城--安华桥: 1018m\n",
      "安华桥--安德里北街: 1274m\n",
      "安德里北街--鼓楼大街: 1083m\n",
      "鼓楼大街--什刹海: 1188m\n",
      "什刹海--南锣鼓巷: 902m\n",
      "\n",
      "----The information of 10号线 is following...\n",
      "巴沟--苏州街: 1110m\n",
      "苏州街--海淀黄庄: 950m\n",
      "海淀黄庄--知春里: 975m\n",
      "知春里--知春路: 1058m\n",
      "知春路--西土城: 1101m\n",
      "西土城--牡丹园: 1330m\n",
      "牡丹园--健德门: 973m\n",
      "健德门--北土城: 1m\n",
      "北土城--安贞门: 1020m\n",
      "安贞门--惠新西街南口: 982m\n",
      "惠新西街南口--芍药居: 1712m\n",
      "芍药居--太阳宫: 1003m\n",
      "太阳宫--三元桥: 1759m\n",
      "三元桥--亮马桥: 1506m\n",
      "亮马桥--农业展览馆: 914m\n",
      "农业展览馆--团结湖: 853m\n",
      "团结湖--呼家楼: 1149m\n",
      "呼家楼--金台夕照: 734m\n",
      "金台夕照--国贸: 835m\n",
      "国贸--双井: 1759m\n",
      "双井--劲松: 1006m\n",
      "劲松--潘家园: 1021m\n",
      "潘家园--十里河: 1097m\n",
      "十里河--分钟寺: 1804m\n",
      "分钟寺--成寿寺: 1058m\n",
      "成寿寺--宋家庄: 1677m\n",
      "宋家庄--石榴庄: 1269m\n",
      "石榴庄--大红门: 1244m\n",
      "大红门--角门东: 1130m\n",
      "角门东--角门西: 1254m\n",
      "角门西--草桥: 1688m\n",
      "草桥--纪家庙: 1547m\n",
      "纪家庙--首经贸: 1143m\n",
      "首经贸--丰台站: 1717m\n",
      "丰台站--泥洼: 954m\n",
      "泥洼--西局: 749m\n",
      "西局--六里桥: 1584m\n",
      "六里桥--莲花桥: 2392m\n",
      "莲花桥--公主坟: 1016m\n",
      "公主坟--西钓鱼台: 2386m\n",
      "西钓鱼台--慈寿寺: 1214m\n",
      "慈寿寺--车道沟: 1590m\n",
      "车道沟--长春桥: 1205m\n",
      "长春桥--火器营: 961m\n",
      "火器营--巴沟: 1495m\n",
      "\n",
      "----The information of 13号线 is following...\n",
      "西直门--大钟寺: 2839m\n",
      "大钟寺--知春路: 1206m\n",
      "知春路--五道口: 1829m\n",
      "五道口--上地: 4866m\n",
      "上地--西二旗: 2538m\n",
      "西二旗--龙泽: 3623m\n",
      "龙泽--回龙观: 1423m\n",
      "回龙观--霍营: 2110m\n",
      "霍营--立水桥: 4785m\n",
      "立水桥--北苑: 2272m\n",
      "北苑--望京西: 6722m\n",
      "望京西--芍药居: 2152m\n",
      "芍药居--光熙门: 1110m\n",
      "光熙门--柳芳: 1135m\n",
      "柳芳--东直门: 1769m\n",
      "\n",
      "----The information of 15号线 is following...\n",
      "清华东路西口--六道口: 1144m\n",
      "六道口--北沙滩: 1337m\n",
      "北沙滩--奥林匹克公园: 1999m\n",
      "奥林匹克公园--安立路: 1368m\n",
      "安立路--大屯路东: 938m\n",
      "大屯路东--关庄: 1087m\n",
      "关庄--望京西: 2071m\n",
      "望京西--望京: 1758m\n",
      "望京--望京东: 1652m\n",
      "望京东--崔各庄: 2295m\n",
      "崔各庄--马泉营: 2008m\n",
      "马泉营--孙河: 3309m\n",
      "孙河--国展: 3386m\n",
      "国展--花梨坎: 1615m\n",
      "花梨坎--后沙峪: 3354m\n",
      "后沙峪--南法信: 4576m\n",
      "南法信--石门: 2712m\n",
      "石门--顺义: 1331m\n",
      "顺义--俸伯: 2441m\n",
      "\n",
      "----The information of 昌平线 is following...\n",
      "昌平西山口--十三陵景区: 1213m\n",
      "十三陵景区--昌平: 3508m\n",
      "昌平--昌平东关: 2433m\n",
      "昌平东关--北邵洼: 1683m\n",
      "北邵洼--南邵: 1958m\n",
      "南邵--沙河高教园: 5357m\n",
      "沙河高教园--沙河: 1964m\n",
      "沙河--巩华城: 2025m\n",
      "巩华城--朱辛庄: 3799m\n",
      "朱辛庄--生命科学园: 2367m\n",
      "生命科学园--西二旗: 5440m\n",
      "\n",
      "----The information of 房山线 is following...\n",
      "郭公庄--大葆台: 1405m\n",
      "大葆台--稻田: 6466m\n",
      "稻田--长阳: 4041m\n",
      "长阳--篱笆房: 2150m\n",
      "篱笆房--广阳城: 1474m\n",
      "广阳城--良乡大学城北: 2003m\n",
      "良乡大学城北--良乡大学城: 1188m\n",
      "良乡大学城--良乡大学城西: 1738m\n",
      "良乡大学城西--良乡南关: 1332m\n",
      "良乡南关--苏庄: 1330m\n",
      "苏庄--阎村东: 2300m\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import collections\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.84 Safari/537.36'\n",
    "}\n",
    "\n",
    "def craw(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "soup = craw('https://baike.baidu.com/item/%E5%8C%97%E4%BA%AC%E5%9C%B0%E9%93%81/408485')\n",
    "lines = soup.findAll('table')[4].findAll('a')[:-1]\n",
    "\n",
    "stations_connection = collections.defaultdict(list)\n",
    "dist = collections.defaultdict(int)\n",
    "node_in_line = collections.defaultdict(set)\n",
    "\n",
    "pattern = re.compile('([\\w|\\d]+)相邻站间距信息统计表')\n",
    "\n",
    "for line in lines[:-3]:\n",
    "    link = 'https://baike.baidu.com' + line.get('href')\n",
    "    soup = craw(link)\n",
    "\n",
    "    for caption in soup.find_all('caption'):\n",
    "        line_name = re.findall(pattern, caption.get_text())\n",
    "        if line_name:\n",
    "            print('\\n----The information of {} is following...'.format(line_name[0]))\n",
    "            table = caption.find_parent('table')\n",
    "            for neigbor in table.find_all('tr')[1:]:\n",
    "                start, end = re.findall(re.compile('([\\w|\\d]+)——([\\w|\\d]+)'), neigbor.th.text)[0]\n",
    "                distance = re.findall(re.compile('([\\d]+)米*'), neigbor.td.text)[0]\n",
    "\n",
    "                stations_connection[start].append(end)\n",
    "                stations_connection[end].append(start)\n",
    "\n",
    "                dist[(start,end)] = dist[(end,start)] = int(distance)\n",
    "    \n",
    "                node_in_line[start].add(line_name[0])\n",
    "                node_in_line[end].add(line_name[0])\n",
    "\n",
    "                print('{}--{}: {}m'.format(start, end, distance))\n",
    "\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手动+自动的Selenium窃取90%网站"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 既然可以手动，那就代表：\n",
    "- 你可以手动关闭弹窗\n",
    "- 手动输入账号密码跨过大部分网站门槛\n",
    "- 手动输入验证码跨过进入壁垒\n",
    "- 还一个优势就是可视化你的爬取过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Example: 爬取兰蔻天猫旗舰店的消费者评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    import re\n",
    "    import requests\n",
    "    import time\n",
    "    from bs4 import BeautifulSoup\n",
    "    from selenium import webdriver\n",
    "\n",
    "    url = 'https://detail.tmall.com/item.htm?spm=a1z10.3-b-s.w4011-14640892229.94.3c6f3c22ejqhZA&id=556028888955&rn=f74615e5cda8e547b07f67e1eb384119&abbucket=16&on_comment=1'\n",
    "    #这里更换目标产品评论网页（天猫兰蔻旗舰店）\n",
    "    driver1 = webdriver.Chrome()#谷歌自动打开之后请手动登陆\n",
    "    driver1.get(url) # 打开网页\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    import pandas as pd\n",
    "    time=[0]*100\n",
    "    review=[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #前四页的“下一页”Xpath不一样；所以先“手动”爬前四页\n",
    "    j=1#爬完一页，手动点击下一页，再j变2，变3，变4；这对于没规律的网站是很难爬，爬取大批量数据建议找有规律的网站，通过循环爬取\n",
    "    for i in range(1,21):\n",
    "        success =False\n",
    "        while not success:\n",
    "            try:\n",
    "                time[(j-1)*20+i-1]=driver1.find_element_by_xpath('//*[@id=\"J_Reviews\"]/div/div[6]/table/tbody/tr['+str(i)+']/td[1]/div[2]').text\n",
    "                review[(j-1)*20+i-1]=driver1.find_element_by_xpath('//*[@id=\"J_Reviews\"]/div/div[6]/table/tbody/tr['+str(i)+']/td[1]/div[1]/div[1]').text\n",
    "                success = True\n",
    "            except:\n",
    "                success=True\n",
    "                pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> selenium入门教学请点击[Christopher's Github](https://github.com/EigenLaw/ChristopherLE-cnblog/tree/master/selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>初次评价:\\n2018.05.03</td>\n",
       "      <td>收货当天追加：\\n宝贝不错值得拥有，有需要的可以下手了，我是给老婆买的，老婆非常喜欢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>初次评价:\\n2017.08.22</td>\n",
       "      <td>收货当天追加：\\n比想象中要好闻！这个香味我很满意！哈哈～</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>留香很持久，越用越喜欢那种</td>\n",
       "      <td>2017.09.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>味道太甜了，讲真，不是我喜欢的类型，就是冲着限量版去的</td>\n",
       "      <td>2017.08.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>超级喜欢，是想象中的味道~香薰蜡烛没有烟火味，大爱~</td>\n",
       "      <td>2018.01.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       reviews                                        time\n",
       "0            初次评价:\\n2018.05.03  收货当天追加：\\n宝贝不错值得拥有，有需要的可以下手了，我是给老婆买的，老婆非常喜欢\n",
       "1            初次评价:\\n2017.08.22               收货当天追加：\\n比想象中要好闻！这个香味我很满意！哈哈～\n",
       "2                留香很持久，越用越喜欢那种                                  2017.09.03\n",
       "3  味道太甜了，讲真，不是我喜欢的类型，就是冲着限量版去的                                  2017.08.22\n",
       "4   超级喜欢，是想象中的味道~香薰蜡烛没有烟火味，大爱~                                  2018.01.02"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    DF1 = pd.DataFrame({\"time\": time, \"reviews\": review})\n",
    "    DF1.head()#由于追加评论导致格式不一致，后期数据清洗也很重要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
